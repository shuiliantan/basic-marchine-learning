### 归一化

方法说明：把某个字段（如value），通过某种方法映射到一定区间内（通常是[-1, 1]或[0, 1]）。常用于数据预处理，可以提升机器学习的训练效率。



### 参数

- **归一化方法**：string类型，可选值为MinMaxScaler、StandardScaler、RobustScaler，具体含义如下：

| 归一化方法     | 归一化方法中文名 | 描述                                                         |
| ----------| ---------------- | ------------------------------------------------------------ |
| MinMaxScaler   | 最大最小归一化    | 对特征进行缩放归一化，默认归一化后特征的数值范围在[0,1]之间。 计算公式为：(x-min)/(max-min) |
| RobustScaler   | 分位数归一化     | 对特征进行缩放归一化，通过 Interquartile Range (IQR) 标准化数据，取四分之一和四分之三分位数为标准进行缩放。计算公式为：(x-中位数)/四分位距 |
| StandardScaler | 标准归一化   | 标准归一化也叫z-score归一化，它将一列特征处理为符合标准正态分布（均值为0，标准差为1）。计算公式为：(x-Mean)/std |


### 解释

一般而言，原始的训练数据中，每一维特征的来源以及度量单位不同，会造成特征的分布范围往往差异很大。当计算不同样本之间的距离时，取值范围大的特征会起到主导作用。对于基于相似度比较的机器学习方法(如最近邻分类器)，必须先对样本进行预处理，将各维度特征归一化到同一取值区间，并且消除不同特征之间的相关性，才能获得理想的结果。


下图是使用标准归一化方法(StandardScaler)对二维数据进行归一化的例子：

- 左图'origin_data'表示的是原始数据；

- 中图'zero-centered data'是原始数据减去均值后的数据，数据被移动到原点周围；

- 右图'normalized_data'将中图得到的数据除以标准差，得到标准化的数据，可以看出每个维度上的尺度是一致的（红色线段的长度表示尺度）。

![image-20181211111029866](http://static.bkdata.oa.com/algorithm/dataprepare/v2/standard_explain.png)